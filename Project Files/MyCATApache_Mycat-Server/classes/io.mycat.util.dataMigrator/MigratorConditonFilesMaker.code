/** 
 * 对具体某个节点重新路由 生成导出数据所依赖的中间文件
 * @author haonan108
 */
public class MigratorConditonFilesMaker implements Runnable {
  private static final Logger LOGGER=LoggerFactory.getLogger(MigratorConditonFilesMaker.class);
  private DataNode srcDn;
  private List<DataNode> newDnList;
  private String column;
  private String tableName;
  private AbstractPartitionAlgorithm alg;
  private String tempFileDir;
  private TableMigrateInfo tableInfo;
  private int newDnSize;
  private int pageSize;
  private Map<DataNode,File> files=new HashMap<>();
  Map<DataNode,StringBuilder> map=new HashMap<>();
  public MigratorConditonFilesMaker(  TableMigrateInfo tableInfo,  DataNode srcDn,  String tempFileDir,  int pageSize){
    this.tableInfo=tableInfo;
    this.tempFileDir=tempFileDir;
    this.srcDn=srcDn;
    this.newDnList=tableInfo.getNewDataNodes();
    this.column=tableInfo.getColumn();
    this.tableName=tableInfo.getTableName();
    this.alg=tableInfo.getNewRuleAlgorithm();
    this.newDnSize=newDnList.size();
    this.pageSize=pageSize;
  }
  @Override public void run(){
    if (tableInfo.isError()) {
      return;
    }
    long[] count=new long[newDnSize];
    int page=0;
    List<Map<String,Object>> list=null;
    Connection con=null;
    try {
      con=DataMigratorUtil.getMysqlConnection(srcDn);
      createTempFiles();
      list=DataMigratorUtil.executeQuery(con,"select " + column + " from "+ tableName+ " limit ?,?",page++ * pageSize,pageSize);
      int total=0;
      while (!CollectionUtil.isEmpty(list)) {
        if (tableInfo.isError()) {
          return;
        }
        flushData(false);
        for (int i=0, l=list.size(); i < l; i++) {
          Map<String,Object> sf=list.get(i);
          Object objFieldVal=sf.get(column);
          String filedVal=objFieldVal.toString();
          if (objFieldVal instanceof String) {
            filedVal="'" + filedVal + "'";
          }
          Integer newIndex=alg.calculate(StringUtil.removeBackquote(objFieldVal.toString()));
          total++;
          DataNode newDn=newDnList.get(newIndex);
          if (!srcDn.equals(newDn)) {
            count[newIndex]++;
            map.get(newDn).append(filedVal + ",");
          }
        }
        list=DataMigratorUtil.executeQuery(con,"select " + column + " from "+ tableName+ " limit ?,?",page++ * pageSize,pageSize);
      }
      flushData(true);
      statisticalData(total,count);
    }
 catch (    Exception e) {
      String message="[" + tableInfo.getSchemaName() + ":"+ tableName+ "]  src dataNode: "+ srcDn.getUrl()+ " prepare temp files is failed! this table's migrator will exit! "+ e.getMessage();
      tableInfo.setError(true);
      tableInfo.setErrMessage(message);
      System.out.println(message);
      LOGGER.error(message,e);
    }
 finally {
      JdbcUtils.close(con);
    }
  }
  private void createTempFiles() throws IOException {
    File parentFile=createDirIfNotExist();
    for (    DataNode dn : newDnList) {
      if (!srcDn.equals(dn)) {
        map.put(dn,new StringBuilder());
        createTempFile(parentFile,dn);
      }
    }
  }
  private void createTempFile(  File parentFile,  DataNode dn) throws IOException {
    File f=new File(parentFile,srcDn.getName() + "(old)" + "-"+ dn.getName()+ "(new).txt");
    if (f.exists()) {
      f.delete();
    }
    f.createNewFile();
    files.put(dn,f);
  }
  private void statisticalData(  int total,  long[] count){
    tableInfo.getSize().addAndGet(total);
    List<DataNodeMigrateInfo> list=tableInfo.getDataNodesDetail();
    List<Long> sizeList=new ArrayList<>();
    for (int i=0; i < count.length; i++) {
      long c=count[i];
      sizeList.add(c);
      DataNode targetDn=newDnList.get(i);
      if (count[i] > 0) {
        DataNodeMigrateInfo info=new DataNodeMigrateInfo(tableInfo,srcDn,targetDn,files.get(targetDn),c);
        list.add(info);
      }
 else {
        File f=files.get(targetDn);
        if (f != null && f.exists()) {
          f.delete();
        }
        files.remove(targetDn);
      }
    }
    Map<String,String> map=tableInfo.getDnMigrateSize();
    map.put(srcDn.getName() + "[" + total+ "]",sizeList.toString());
  }
  private void flushData(  boolean isForce) throws IOException {
    for (    DataNode dn : newDnList) {
      StringBuilder sb=map.get(dn);
      if (sb == null) {
        continue;
      }
      if ((isForce || sb.toString().getBytes().length > 1024) && sb.length() > 0) {
        String s=sb.toString();
        if (isForce) {
          s=s.substring(0,s.length() - 1);
        }
        DataMigratorUtil.appendDataToFile(files.get(dn),s);
        sb=new StringBuilder();
        map.put(dn,sb);
      }
    }
  }
  private File createDirIfNotExist(){
    File f=new File(tempFileDir,tableInfo.getSchemaName() + "-" + tableName);
    if (!f.exists()) {
      f.mkdirs();
    }
    return f;
  }
}
