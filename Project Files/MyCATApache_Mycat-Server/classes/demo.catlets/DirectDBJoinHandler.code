class DirectDBJoinHandler implements SQLJobHandler {
  private List<byte[]> fields;
  private final EngineCtx ctx;
  public DirectDBJoinHandler(  EngineCtx ctx){
    super();
    this.ctx=ctx;
  }
  private Map<String,byte[]> rows=new ConcurrentHashMap<String,byte[]>();
  private ConcurrentLinkedQueue<String> ids=new ConcurrentLinkedQueue<String>();
  @Override public void onHeader(  String dataNode,  byte[] header,  List<byte[]> fields){
    this.fields=fields;
  }
  private void createQryJob(  int batchSize){
    int count=0;
    Map<String,byte[]> batchRows=new ConcurrentHashMap<String,byte[]>();
    String theId=null;
    StringBuilder sb=new StringBuilder().append('(');
    while ((theId=ids.poll()) != null) {
      batchRows.put(theId,rows.remove(theId));
      sb.append(theId).append(',');
      if (count++ > batchSize) {
        break;
      }
    }
    if (count == 0) {
      return;
    }
    sb.deleteCharAt(sb.length() - 1).append(')');
    String querySQL="select b.id, b.title  from hotnews b where id in " + sb;
    ctx.executeNativeSQLParallJob(new String[]{"dn1","dn2","dn3"},querySQL,new MyRowOutPutDataHandler(fields,ctx,batchRows));
  }
  @Override public boolean onRowData(  String dataNode,  byte[] rowData){
    String id=ResultSetUtil.getColumnValAsString(rowData,fields,0);
    rows.put(id,rowData);
    ids.offer(id);
    int batchSize=999;
    if (ids.size() > batchSize) {
      createQryJob(batchSize);
    }
    return false;
  }
  @Override public void finished(  String dataNode,  boolean failed,  String errorMsg){
    if (!failed) {
      createQryJob(Integer.MAX_VALUE);
    }
    ctx.endJobInput();
  }
}
